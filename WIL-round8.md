# WIL - 8주차 (Hello, Kafka!)

## 🧠 이번 주에 새로 배운 것
- Kafka Producer & Consumer
- At Most Once / At Least Once / Exactly Once
- Idempotency & 멱등 처리
- Dead Letter Queue (DLQ)

## 💭 이런 고민이 있었어요
1. 카프카 대체 왜 쓸까?
	•	비동기 처리: 주문/좋아요/재고 변경 같은 이벤트를 바로 처리하지 않고 큐에 넣어두고 나중에 처리 → 서비스 간 결합 줄임.
	•	확장성: 이벤트 소비자를 여러 개 늘려도 메시지 순서/분배를 카프카가 보장해줌 → 트래픽 많이 터져도 대응 가능.
	•	내구성: 이벤트 로그를 디스크에 영속화해서 장애나 재시작 시에도 데이터 유실 방지.
	•	재처리 가능성: 메시지를 다시 읽어서 분석, 집계, 리플레이 같은 작업이 가능.
2. 카프카도 유실될 경우
	•	Producer 측: acks=0이나 네트워크 오류 시 메시지가 브로커에 도달하지 못할 수 있음. (acks=all, retries 설정으로 완화)
	•	Broker 측: 리플리케이션 팩터가 낮거나 ISR(동기화 레플리카) 관리가 잘 안 되면 브로커 장애 시 유실 가능. (replication.factor >= 3 권장)
	•	Consumer 측: 오프셋 커밋 전에 장애가 나면 같은 메시지를 중복 처리하거나, 잘못 커밋하면 메시지를 놓칠 수도 있음. (manual commit + 멱등 처리로 완화)
3. DLQ
	•	실패 메시지 보관: 소비자가 메시지를 처리하지 못했을 때 유실되는 대신 DLQ로 보냄
	•	원인 추적 가능: 쌓인 메시지를 기반으로 오류 원인을 분석할 수 있음
	•	재처리 or 폐기 결정: 운영자가 상황에 따라 메시지를 다시 처리하거나 버릴 수 있음
4. topic을 나누는 기준
	•	도메인/업무 단위: 상품(catalog), 주문(order), 결제(payment)처럼 성격이 다른 이벤트는 분리
	•	트래픽 패턴 차이: 조회성 이벤트(많음)와 결제 이벤트(적음)처럼 발생 빈도가 다르면 분리
	•	소비자 그룹 독립성: 특정 이벤트만 필요로 하는 컨슈머가 있다면 해당 이벤트 전용 토픽으로 분리
5. 이벤트 순서 보장의 중요성
	•	Kafka는 같은 파티션 안에서는 메시지 순서를 보장하지만, 서로 다른 파티션 간에는 순서 보장이 되지 않는다.
	•	따라서 순서가 중요한 이벤트는 같은 파티션 키(예: productId, userId)를 기준으로 묶어서 보내야 한다.
	•	예를 들어, 좋아요 이벤트의 경우:
	1.	LikeCreatedEvent(user-1, product-1001)
	2.	LikeCancelledEvent(user-1, product-1001)

→ 이 순서가 보장되어야 최종 상태가 “좋아요 없음”으로 맞게 처리된다.

→ 만약 순서가 뒤바뀌면 최종 상태가 “좋아요 있음”으로 잘못될 수 있다.

## 💡 앞으로 실무에 써먹을 수 있을 것 같은 포인트
- 사실 트래픽이 적은 시스템은 카프카를 도입할 이유가 없긴 한 것 같다.
- 그래도 도입할 .. 부분을 찾아보거나 고민해보는 건 좋을 것 같음

## 🤔 아쉬웠던 점 & 다음 주에 해보고 싶은 것
- Dead Letter Queue (DLQ) 를 사용하여 이벤트 실패 시 대응을 구현하지 못한 것이 아쉬웠다.
- 새로운 개념에 혼란이 와서 과제 진도가 늦었는데 .. 요 과정이 끝나면 카프카 마스터 해보고 싶다.
